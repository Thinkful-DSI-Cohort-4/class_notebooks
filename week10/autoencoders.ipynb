{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our autoencoder layers for our goofy exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Person</th>\n",
       "      <th>Words Allowed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer Number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Encoder</td>\n",
       "      <td>Adam S.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Encoder</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Encoder</td>\n",
       "      <td>Jon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Code</td>\n",
       "      <td>Shobair</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decoder</td>\n",
       "      <td>Wyatt</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decoder</td>\n",
       "      <td>Heather</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decoder</td>\n",
       "      <td>Michael</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Layer Type   Person  Words Allowed\n",
       "Layer Number                                   \n",
       "1               Encoder  Adam S.             10\n",
       "2               Encoder   Hunter              8\n",
       "3               Encoder      Jon              6\n",
       "4                  Code  Shobair              3\n",
       "5               Decoder    Wyatt              6\n",
       "6               Decoder  Heather              8\n",
       "7               Decoder  Michael             10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"import random\\nimport pandas as pd\\n\\nrandom.seed(42)\\n\\nnames = [\\n    \\\"Adam P.\\\",\\n    \\\"Emily\\\",\\n    \\\"Heather\\\",\\n    \\\"Hunter\\\",\\n    \\\"Jon\\\",\\n    \\\"Michael\\\",\\n    \\\"Shobair\\\",\\n    \\\"Wyatt\\\",\\n]\\nrandom.shuffle(names)\\n\\ninput_layer = [\\\"Adam S.\\\"]\\nremaining_layers = names[:6]\\n\\nlayers = input_layer + remaining_layers\\nlayer_type = [\\\"Encoder\\\"] * 3 + [\\\"Code\\\"] + [\\\"Decoder\\\"] * 3\\nwords_allowed = [10, 8, 6, 3, 6, 8, 10]\\n\\ndf = pd.DataFrame(\\n    {\\\"Layer Type\\\": layer_type, \\\"Person\\\": layers, \\\"Words Allowed\\\": words_allowed}\\n)\\ndf.index += 1\\ndf.index.name = \\\"Layer Number\\\"\\ndf\";\n",
       "                var nbb_formatted_code = \"import random\\nimport pandas as pd\\n\\nrandom.seed(42)\\n\\nnames = [\\n    \\\"Adam P.\\\",\\n    \\\"Emily\\\",\\n    \\\"Heather\\\",\\n    \\\"Hunter\\\",\\n    \\\"Jon\\\",\\n    \\\"Michael\\\",\\n    \\\"Shobair\\\",\\n    \\\"Wyatt\\\",\\n]\\nrandom.shuffle(names)\\n\\ninput_layer = [\\\"Adam S.\\\"]\\nremaining_layers = names[:6]\\n\\nlayers = input_layer + remaining_layers\\nlayer_type = [\\\"Encoder\\\"] * 3 + [\\\"Code\\\"] + [\\\"Decoder\\\"] * 3\\nwords_allowed = [10, 8, 6, 3, 6, 8, 10]\\n\\ndf = pd.DataFrame(\\n    {\\\"Layer Type\\\": layer_type, \\\"Person\\\": layers, \\\"Words Allowed\\\": words_allowed}\\n)\\ndf.index += 1\\ndf.index.name = \\\"Layer Number\\\"\\ndf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "names = [\n",
    "    \"Adam P.\",\n",
    "    \"Emily\",\n",
    "    \"Heather\",\n",
    "    \"Hunter\",\n",
    "    \"Jon\",\n",
    "    \"Michael\",\n",
    "    \"Shobair\",\n",
    "    \"Wyatt\",\n",
    "]\n",
    "random.shuffle(names)\n",
    "\n",
    "input_layer = [\"Adam S.\"]\n",
    "remaining_layers = names[:6]\n",
    "\n",
    "layers = input_layer + remaining_layers\n",
    "layer_type = [\"Encoder\"] * 3 + [\"Code\"] + [\"Decoder\"] * 3\n",
    "words_allowed = [10, 8, 6, 3, 6, 8, 10]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"Layer Type\": layer_type, \"Person\": layers, \"Words Allowed\": words_allowed}\n",
    ")\n",
    "df.index += 1\n",
    "df.index.name = \"Layer Number\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 1:\n",
    "\n",
    "```\n",
    "* Input Phrase (Layer 1):\n",
    "    * \"Why fit in when you were born to stand out\"\n",
    "* Encoded Phrase (Layer 4):\n",
    "    * \"Fit Stand Out\"\n",
    "* Output Phrase (Layer 7):  \n",
    "    * \"Please fit a good stand out model very fast now\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round 2:\n",
    "\n",
    "```\n",
    "* Input Phrase (Layer 1):\n",
    "    * \"A way to a mans heart is through his stomach\"\n",
    "* Encoded Phrase (Layer 4):\n",
    "    * \"man's heart stomach\"\n",
    "* Output Phrase (Layer 7):  \n",
    "    * \"the way to a man's heart is through his stomach\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game:\n",
    "\n",
    "* Adam S. will be our input layer, he will pass on a 10 word phrase to the 2nd layer\n",
    "* The 2nd layer must summarize the 10 word phrase to 8 words with the goal of retaining the true meaning of the phrase as best as possible\n",
    "    * Repeat this process up to the code layer (layer 4)\n",
    "* The code layer will pass on their 3 word summary to layer 5 who must try and unsummarize the 3 word summary into a 6 word summary\n",
    "    * Repeat this process up to the last layer\n",
    "* The final layer will have an output of a 10 word phrase and we'll compare the output phrase to the input phrase\n",
    "\n",
    "How to play with Slack:\n",
    "\n",
    "* If you are a (p)layer, wait for a phrase to be sent to you by the person before you.\n",
    "* Translate the phrase into your specified number of words, and send this as a direct to the (p)layer after you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "<img src='https://miro.medium.com/max/3148/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png' width=70%>\n",
    "\n",
    "To demo what an autoencoder is doing, let's play a game of telephone that mirrors the encoding/decoding shown above.\n",
    "\n",
    "Person 1 is the first layer (colored blue), Person 2 is the second layer (colored green), ..., and Person 7 is the last layer (colored blue).\n",
    "\n",
    "## Encoding layer\n",
    "\n",
    "Person 1 will be our input layer, let's say our input data is a 10 word phrase (to match the number of blocks in the image).  Person 1 will tell Person 2 this 10 word phrase and Person 2's job is to figure out how to compress this phrase down to 8 words.\n",
    "\n",
    "Person 2 will then tell Person 3 this 8 word summarization of the origninal phrase.  Person 3 now has to summarize this phrase to 6 words.\n",
    "\n",
    "Person 3 passes this message to Person 4 who has to summarize down to 3 words.\n",
    "\n",
    "This 3 word summary is our encoded representation of our data.  It is a reduced dimension version of the data, the rest of the process (the decoder) is to figure out if this is a good summarization.\n",
    "\n",
    "## Decoding layer\n",
    "\n",
    "Person 4 (the code layer) tells their 3 word summary to Person 5.  Instead of summarizing, Person 5's job is to expand this summary into 6 words.\n",
    "\n",
    "Person 5 passes this expanded summary to Person 6 who expands it to 8 words and passes it along to our final Person 7 (the output layer).\n",
    "\n",
    "Person 7 expands the summary back to the original 10 words, and now we compare how close this output is to the input.  There's likely to be some loss of information.\n",
    "\n",
    "Our goal is to iterate on this game of telephone until Person 7 is able to recreate the input phrase as closely as possible.  If our output is very similar to our input, then the code layer has a very good summary of the input data.  We can use this lower dimension representation of our data thats found in the code layer for visualization/supervised learning.\n",
    "\n",
    "## Toy Example\n",
    "\n",
    "For example, this telphone phrase might be:\n",
    "\n",
    "An early iteration might be very bad at recreating the input:\n",
    "\n",
    "```\n",
    "Layer 1 / Input layer:  \"the rain in spain falls very neatly on the plain\"\n",
    "Layer 2:                \"the in falls very neatly on the plain\"\n",
    "Layer 3:                \"the in very neatly on the\"\n",
    "Layer 4 / Code layer:   \"the on the\"\n",
    "Layer 5:                \"puts the lotion on the skin\"\n",
    "Layer 6:                \"it puts the lotion on the skin or\"\n",
    "Layer 7 / Output layer: \"it puts the lotion on the skin or it gets\"\n",
    "```\n",
    "\n",
    "Our input phrase was very ESL and our output is Buffalo Bill.  This indicates that the code layer is a bad summary of the data.  The code layer has still performed dimension reduction, but it doesn't contain useful information.\n",
    "\n",
    "A later iteration will hopefully be better at learning the data.\n",
    "\n",
    "```\n",
    "Layer 1 / Input layer:  \"the rain in spain falls very neatly on the plain\"\n",
    "Layer 2:                \"rain in spain falls neatly on the plain\"\n",
    "Layer 3:                \"rain in spain falls on plain\"\n",
    "Layer 4 / Code layer:   \"rain spain plain\"\n",
    "Layer 5:                \"rain spain falls on the plain\"\n",
    "Layer 6:                \"rain in spain falls neatly on the plain\"\n",
    "Layer 7 / Output layer: \"rain in spain falls neatly on the great spain plain\"\n",
    "```\n",
    "\n",
    "We could now use the code layer (`\"rain spain plain\"`) to serve as a lower dimensional representation of our input data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
